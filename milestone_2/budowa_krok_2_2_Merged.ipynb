{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etap 2\n",
    "Z ostatniego etapu otrzymaliśmy zdjęcia przygotowane do następnego etapu i zapisane w foldderze 'output'.\n",
    "Budując i testując modele musimy zwrócić uwagę na brak zbalansowania zbioru. Będziemy się starać balansować zbiór, tak aby Accuracy wykorzystywane do stopnia wytrenowania modelu było adekwatną miarą oceny."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pierwsze podejście\n",
    "Do tej grupy modelów balansowanie zbiorów uzyskaliśmy za pomocą obrotów i odbić i ponownego zapisu plików do folderu 'output_balanced'. Ze względu na konieczność przechowywania dużej liczby zdjęć nie jest to najlepsze wyjście, ale jest to nasz punkt startowy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balansowanie - Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja balansująca klasy. Wynik folder 'output_balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_root = \"output\"\n",
    "output_root = \"output_balanced\"\n",
    "\n",
    "augmentation_times = {\n",
    "    \"Normal\": [\"h\", \"v\"],  # 2 razy więcej \n",
    "    \"AVM\": [\"h90\", \"h180\", \"h270\", \"v90\", \"v180\", \"v270\"],  # 6 razy więcej\n",
    "    \"Ulcer\": [\"h\", \"h90\", \"h180\", \"h270\", \"v\", \"v90\", \"v180\", \"v270\"],  # 8 razy więcej \n",
    "}\n",
    "\n",
    "for root, _, files in os.walk(input_root):\n",
    "    class_name = os.path.basename(root)  \n",
    "\n",
    "    if class_name not in augmentation_times:\n",
    "        continue \n",
    "\n",
    "    for file in files:\n",
    "        if not file.endswith(\".bmp\"):\n",
    "            continue \n",
    "\n",
    "        input_path = os.path.join(root, file)\n",
    "\n",
    "        relative_path = os.path.relpath(root, input_root)\n",
    "        output_dir = os.path.join(output_root, relative_path)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        base, ext = os.path.splitext(file)\n",
    "        variants = augmentation_times[class_name]\n",
    "\n",
    "        image = cv2.imread(input_path)\n",
    "\n",
    "        transformed_images = {\n",
    "            \"base\" : image,\n",
    "            \"h\": cv2.flip(image, 1),\n",
    "            \"v\": cv2.flip(image, 0),\n",
    "            \"90\": cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE),\n",
    "            \"180\": cv2.rotate(image, cv2.ROTATE_180),\n",
    "            \"270\": cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "            \"h90\": cv2.flip(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE), 1),\n",
    "            \"h180\": cv2.flip(cv2.rotate(image, cv2.ROTATE_180), 1),\n",
    "            \"h270\": cv2.flip(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE), 1),\n",
    "            \"v90\": cv2.flip(cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE), 0),\n",
    "            \"v180\": cv2.flip(cv2.rotate(image, cv2.ROTATE_180), 0),\n",
    "            \"v270\": cv2.flip(cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE), 0)\n",
    "        }\n",
    "\n",
    "        # Zapisujemy tylko te transformacje, które są w augmentation_config dla danej klasy\n",
    "        for variant in variants:\n",
    "            output_path = os.path.join(output_dir, f\"{base}{variant}{ext}\")\n",
    "            cv2.imwrite(output_path, transformed_images[variant])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie rozkładu klas po balansowaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nazwa klasy</th>\n",
       "      <th>Liczba zdjęć</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVM</td>\n",
       "      <td>4008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ulcer</td>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nazwa klasy  Liczba zdjęć\n",
       "0         AVM          4008\n",
       "1      Normal          4304\n",
       "2       Ulcer          3720"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_folder = \"output_balanced\"\n",
    "output_data = []  \n",
    "\n",
    "for folder in os.listdir(parent_folder):\n",
    "    folder_path = os.path.join(parent_folder, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        count = sum(1 for f in os.listdir(folder_path) if f.endswith(\".bmp\"))\n",
    "        output_data.append([folder, count])  \n",
    "df_output = pd.DataFrame(output_data, columns=[\"Nazwa klasy\", \"Liczba zdjęć\"])\n",
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procent zbalansowania: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procent zbalansowania: 86.43%\n"
     ]
    }
   ],
   "source": [
    "proc_balanced = df_output.loc[2, \"Liczba zdjęć\"] /df_output.loc[1, \"Liczba zdjęć\"] *100\n",
    "print(f\"Procent zbalansowania: {proc_balanced:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVM': 0, 'Ulcer': 1, 'Normal': 2}\n"
     ]
    }
   ],
   "source": [
    "def save_to_list():\n",
    "    output_root = \"output_balanced\"\n",
    "    X = []\n",
    "    y = []\n",
    "    label_to_index = {\n",
    "        label: idx for idx, label in enumerate({'AVM', 'Normal', 'Ulcer'})\n",
    "    }\n",
    "    print(label_to_index)\n",
    "    for root, _, files in os.walk(output_root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bmp\"): \n",
    "                input_path = os.path.join(root, file)\n",
    "\n",
    "                base, ext = os.path.splitext(file)\n",
    "                new_filename = f\"{base}{ext}\"\n",
    "                image = cv2.imread(input_path)\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label_to_index[new_filename.split(\"_\")[0]])\n",
    "    return X, y\n",
    "\n",
    "X, y = save_to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratify w celu zachowania równowagi pomiędzy zbiorami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/balanced-sampling-between-classes-with-torchvision-dataloader/2703/2\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx])  \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long) \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla zbioru treningowego dodajemy rotacje odpicia w celu większego urozmaicenia zdjęć (augumentacja). Dla zbioru testowego tylko zmiana rozmiaru i normalizacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          \n",
    "    transforms.RandomRotation((-30,30)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])  \n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = ImageDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funckcje do treningu i ewaluacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja trenująca i oceniająca za pomocą Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, epochs=10, learning_rate=0.001, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    print(f\"Using device: {device}\") \n",
    "    model.to(device)\n",
    "  \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    print('PRZED EPOKAMI')\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        print('po model.train')\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        print('po zerowaniu poprawnych i całkowitych')\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "    print('po epokach')\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja trenująca i oceniająca za pomocą większej liczby metryk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_more_metrics(model, train_loader, test_loader, epochs=10, learning_rate=0.001, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    print(f\"Using device: {device}\") \n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())  \n",
    "            all_predictions.extend(predicted.cpu().numpy())  \n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        train_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "        train_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    test_precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_f1 = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
    "    test_conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}%, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", test_conf_matrix)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Droput(0.5) <- zapobiega overfittingowi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),  # ewentualnie dodać jeszcze jedną warstwę pośrednią\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # zapobieganie overfittingowi\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z użyciem optimizer AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/15, Loss: 0.9449, Train Acc: 54.93%, Precision: 0.5637, Recall: 0.5493, F1: 0.5400\n",
      "Epoch 2/15, Loss: 0.7370, Train Acc: 68.48%, Precision: 0.7006, Recall: 0.6848, F1: 0.6869\n",
      "Epoch 3/15, Loss: 0.6324, Train Acc: 74.83%, Precision: 0.7580, Recall: 0.7483, F1: 0.7501\n",
      "Epoch 4/15, Loss: 0.5342, Train Acc: 79.66%, Precision: 0.8017, Recall: 0.7966, F1: 0.7977\n",
      "Epoch 5/15, Loss: 0.4403, Train Acc: 83.33%, Precision: 0.8374, Recall: 0.8333, F1: 0.8341\n",
      "Epoch 6/15, Loss: 0.3745, Train Acc: 86.19%, Precision: 0.8657, Recall: 0.8619, F1: 0.8626\n",
      "Epoch 7/15, Loss: 0.3275, Train Acc: 87.60%, Precision: 0.8791, Recall: 0.8760, F1: 0.8764\n",
      "Epoch 8/15, Loss: 0.3099, Train Acc: 88.22%, Precision: 0.8855, Recall: 0.8822, F1: 0.8827\n",
      "Epoch 9/15, Loss: 0.2623, Train Acc: 90.29%, Precision: 0.9057, Recall: 0.9029, F1: 0.9033\n",
      "Epoch 10/15, Loss: 0.2396, Train Acc: 91.01%, Precision: 0.9120, Recall: 0.9101, F1: 0.9103\n",
      "Epoch 11/15, Loss: 0.2186, Train Acc: 91.69%, Precision: 0.9187, Recall: 0.9169, F1: 0.9172\n",
      "Epoch 12/15, Loss: 0.2037, Train Acc: 92.43%, Precision: 0.9257, Recall: 0.9243, F1: 0.9246\n",
      "Epoch 13/15, Loss: 0.1888, Train Acc: 92.79%, Precision: 0.9291, Recall: 0.9279, F1: 0.9281\n",
      "Epoch 14/15, Loss: 0.1715, Train Acc: 93.46%, Precision: 0.9356, Recall: 0.9346, F1: 0.9348\n",
      "Epoch 15/15, Loss: 0.1667, Train Acc: 93.86%, Precision: 0.9392, Recall: 0.9386, F1: 0.9387\n",
      "Test Accuracy: 94.14%, Precision: 0.9442, Recall: 0.9414, F1: 0.9418\n",
      "Confusion Matrix:\n",
      " [[528   1  27]\n",
      " [  2 541  51]\n",
      " [ 17   7 618]]\n"
     ]
    }
   ],
   "source": [
    "model_1 = CNNModel(num_classes=3)\n",
    "trained_model_1 = train_and_evaluate_more_metrics(model_1, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model_1.state_dict(), \"trained_model_1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z użyceim optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "cuda:0\n",
      "Epoch 1/15, Loss: 0.9190, Train Acc: 58.41%, Precision: 0.6029, Recall: 0.5841, F1: 0.5847\n",
      "Epoch 2/15, Loss: 0.7864, Train Acc: 65.14%, Precision: 0.6687, Recall: 0.6514, F1: 0.6548\n",
      "Epoch 3/15, Loss: 0.7366, Train Acc: 68.23%, Precision: 0.6987, Recall: 0.6823, F1: 0.6853\n",
      "Epoch 4/15, Loss: 0.6682, Train Acc: 71.99%, Precision: 0.7316, Recall: 0.7199, F1: 0.7222\n",
      "Epoch 5/15, Loss: 0.5827, Train Acc: 76.78%, Precision: 0.7792, Recall: 0.7678, F1: 0.7689\n",
      "Epoch 6/15, Loss: 0.4708, Train Acc: 81.73%, Precision: 0.8237, Recall: 0.8173, F1: 0.8177\n",
      "Epoch 7/15, Loss: 0.4285, Train Acc: 83.99%, Precision: 0.8436, Recall: 0.8399, F1: 0.8403\n",
      "Epoch 8/15, Loss: 0.3707, Train Acc: 86.20%, Precision: 0.8660, Recall: 0.8620, F1: 0.8623\n",
      "Epoch 9/15, Loss: 0.3201, Train Acc: 87.71%, Precision: 0.8799, Recall: 0.8771, F1: 0.8774\n",
      "Epoch 10/15, Loss: 0.3233, Train Acc: 87.92%, Precision: 0.8821, Recall: 0.8792, F1: 0.8795\n",
      "Epoch 11/15, Loss: 0.2817, Train Acc: 89.50%, Precision: 0.8976, Recall: 0.8950, F1: 0.8952\n",
      "Epoch 12/15, Loss: 0.2566, Train Acc: 90.33%, Precision: 0.9060, Recall: 0.9033, F1: 0.9035\n",
      "Epoch 13/15, Loss: 0.2559, Train Acc: 90.20%, Precision: 0.9048, Recall: 0.9020, F1: 0.9022\n",
      "Epoch 14/15, Loss: 0.2326, Train Acc: 91.11%, Precision: 0.9138, Recall: 0.9111, F1: 0.9115\n",
      "Epoch 15/15, Loss: 0.2296, Train Acc: 91.09%, Precision: 0.9130, Recall: 0.9109, F1: 0.9111\n",
      "Test Accuracy: 92.08%, Precision: 0.9257, Recall: 0.9208, F1: 0.9207\n",
      "Confusion Matrix:\n",
      " [[537   0  19]\n",
      " [ 20 505  69]\n",
      " [ 30   4 608]]\n"
     ]
    }
   ],
   "source": [
    "model_1 = CNNModel(num_classes=3)\n",
    "trained_model_1_2 = train_and_evaluate_more_metrics(model_1, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model_1_2.state_dict(), \"trained_model_1_2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodanie innych metryk nie wniosło nowych informacji poza tym, że dane są dobrze zbalansowane oraz model dobrze generalizuje.\n",
    "Interpretacja ConfusionMatrix: Na przekątnej wartości dobrze zidentyfikowane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model zmienił funkcję aktywacji z ReLU na LeakyReLU, która przepuszcza wartośći ujemne w pewnym stopniu (ustawiony na 0.1).\n",
    "ReLU : jeśli otrzyma dużą liczbę ujmenych wartości to gradient może zatrzymać się na 0 i przestać się uczyć.\n",
    "LeakyReLU: jesli otrzyma dużą liczbę ujmenych wartość to gradient nie będzie 0 tylko mały i proces uczenia nie zatrzyma się.\n",
    "Czy otrzymamy lepsze wyniki??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_gradient(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel_gradient, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),  # LeakyReLU zamiast ReLU\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),  # LeakyReLU zamiast ReLU\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.1),  # LeakyReLU zamiast ReLU\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),  # ewentualnie dodać jeszcze jedną warstwę pośrednią\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # zapobieganie overfittingowi\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/15, Loss: 0.8916, Train Acc: 62.48%, Precision: 0.6338, Recall: 0.6248, F1: 0.6266\n",
      "Epoch 2/15, Loss: 0.5250, Train Acc: 79.40%, Precision: 0.7961, Recall: 0.7940, F1: 0.7942\n",
      "Epoch 3/15, Loss: 0.4462, Train Acc: 83.29%, Precision: 0.8360, Recall: 0.8329, F1: 0.8333\n",
      "Epoch 4/15, Loss: 0.4056, Train Acc: 84.79%, Precision: 0.8508, Recall: 0.8479, F1: 0.8483\n",
      "Epoch 5/15, Loss: 0.4107, Train Acc: 84.92%, Precision: 0.8517, Recall: 0.8492, F1: 0.8495\n",
      "Epoch 6/15, Loss: 0.3276, Train Acc: 87.90%, Precision: 0.8813, Recall: 0.8790, F1: 0.8793\n",
      "Epoch 7/15, Loss: 0.3290, Train Acc: 87.51%, Precision: 0.8774, Recall: 0.8751, F1: 0.8753\n",
      "Epoch 8/15, Loss: 0.2905, Train Acc: 89.23%, Precision: 0.8942, Recall: 0.8923, F1: 0.8925\n",
      "Epoch 9/15, Loss: 0.3133, Train Acc: 88.15%, Precision: 0.8837, Recall: 0.8815, F1: 0.8818\n",
      "Epoch 10/15, Loss: 0.2855, Train Acc: 89.27%, Precision: 0.8942, Recall: 0.8927, F1: 0.8929\n",
      "Epoch 11/15, Loss: 0.2814, Train Acc: 89.54%, Precision: 0.8975, Recall: 0.8954, F1: 0.8957\n",
      "Epoch 12/15, Loss: 0.2927, Train Acc: 89.21%, Precision: 0.8942, Recall: 0.8921, F1: 0.8924\n",
      "Epoch 13/15, Loss: 0.2691, Train Acc: 90.09%, Precision: 0.9022, Recall: 0.9009, F1: 0.9011\n",
      "Epoch 14/15, Loss: 0.2950, Train Acc: 89.28%, Precision: 0.8946, Recall: 0.8928, F1: 0.8931\n",
      "Epoch 15/15, Loss: 0.2267, Train Acc: 91.24%, Precision: 0.9133, Recall: 0.9124, F1: 0.9125\n",
      "Test Accuracy: 90.01%, Precision: 0.9129, Recall: 0.9001, F1: 0.9015\n",
      "Confusion Matrix:\n",
      " [[513  79   4]\n",
      " [ 10 620  10]\n",
      " [  2  74 480]]\n"
     ]
    }
   ],
   "source": [
    "model2 = CNNModel_gradient(num_classes=3)\n",
    "trained_model2 = train_and_evaluate_more_metrics(model2, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model2.state_dict(), \"model2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU może powodować, że gradienty są mniejsze dla wartości ujemnych, co może spowolnić uczenie się w pewnych przypadkach. -> widzimy spadek accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmiana nn.Dropout na 0.2 -> sprawdzenie czy w przypadku 1 modelu nie zachodizło zjawisko underfittingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_lower_dropout(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel_lower_dropout, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512),  # ewentualnie dodać jeszcze jedną warstwę pośrednią\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2), # zapobieganie overfittingowi\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/15, Loss: 0.9671, Train Acc: 56.30%, Precision: 0.5912, Recall: 0.5630, F1: 0.5621\n",
      "Epoch 2/15, Loss: 0.7751, Train Acc: 64.70%, Precision: 0.6666, Recall: 0.6470, F1: 0.6504\n",
      "Epoch 3/15, Loss: 0.6831, Train Acc: 71.00%, Precision: 0.7176, Recall: 0.7100, F1: 0.7121\n",
      "Epoch 4/15, Loss: 0.6009, Train Acc: 75.11%, Precision: 0.7559, Recall: 0.7511, F1: 0.7525\n",
      "Epoch 5/15, Loss: 0.5445, Train Acc: 77.95%, Precision: 0.7846, Recall: 0.7795, F1: 0.7806\n",
      "Epoch 6/15, Loss: 0.4516, Train Acc: 82.06%, Precision: 0.8233, Recall: 0.8206, F1: 0.8210\n",
      "Epoch 7/15, Loss: 0.3827, Train Acc: 85.14%, Precision: 0.8533, Recall: 0.8514, F1: 0.8515\n",
      "Epoch 8/15, Loss: 0.3287, Train Acc: 87.37%, Precision: 0.8759, Recall: 0.8737, F1: 0.8739\n",
      "Epoch 9/15, Loss: 0.2936, Train Acc: 88.78%, Precision: 0.8902, Recall: 0.8878, F1: 0.8881\n",
      "Epoch 10/15, Loss: 0.2695, Train Acc: 89.56%, Precision: 0.8975, Recall: 0.8956, F1: 0.8958\n",
      "Epoch 11/15, Loss: 0.2671, Train Acc: 89.98%, Precision: 0.9013, Recall: 0.8998, F1: 0.9000\n",
      "Epoch 12/15, Loss: 0.2373, Train Acc: 91.15%, Precision: 0.9133, Recall: 0.9115, F1: 0.9117\n",
      "Epoch 13/15, Loss: 0.2172, Train Acc: 91.61%, Precision: 0.9176, Recall: 0.9161, F1: 0.9163\n",
      "Epoch 14/15, Loss: 0.2147, Train Acc: 91.68%, Precision: 0.9180, Recall: 0.9168, F1: 0.9170\n",
      "Epoch 15/15, Loss: 0.2013, Train Acc: 92.31%, Precision: 0.9243, Recall: 0.9231, F1: 0.9233\n",
      "Test Accuracy: 92.52%, Precision: 0.9305, Recall: 0.9252, F1: 0.9258\n",
      "Confusion Matrix:\n",
      " [[523  67   6]\n",
      " [  5 613  22]\n",
      " [  0  34 522]]\n"
     ]
    }
   ],
   "source": [
    "model3 = CNNModel_lower_dropout(num_classes=3)\n",
    "trained_model3 = train_and_evaluate_more_metrics(model3, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model3.state_dict(), \"model3.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zwiększenie ilości filtrów. dla małego zbiru danych może nie być najlepsze, ponieważ model może zacząć się uczyć na pamięć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_more_filters(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel_more_filters, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 28 * 28, 512),  # -> tu ustawiamy liczbę filtrów w ostatniej warstwie konwolucyjnej czyli Conv2d razy wymiary po wszystkich maxPoolach\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # zapobieganie overfittingowi\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/15, Loss: 1.1168, Train Acc: 48.37%, Precision: 0.4864, Recall: 0.4837, F1: 0.4509\n",
      "Epoch 2/15, Loss: 0.9136, Train Acc: 54.41%, Precision: 0.6105, Recall: 0.5441, F1: 0.5113\n",
      "Epoch 3/15, Loss: 0.8660, Train Acc: 58.14%, Precision: 0.6357, Recall: 0.5814, F1: 0.5715\n",
      "Epoch 4/15, Loss: 0.8328, Train Acc: 61.44%, Precision: 0.6606, Recall: 0.6144, F1: 0.6111\n",
      "Epoch 5/15, Loss: 0.8333, Train Acc: 61.82%, Precision: 0.6505, Recall: 0.6182, F1: 0.6189\n",
      "Epoch 6/15, Loss: 0.7284, Train Acc: 68.06%, Precision: 0.7028, Recall: 0.6806, F1: 0.6836\n",
      "Epoch 7/15, Loss: 0.6378, Train Acc: 73.10%, Precision: 0.7466, Recall: 0.7310, F1: 0.7333\n",
      "Epoch 8/15, Loss: 0.5795, Train Acc: 76.79%, Precision: 0.7766, Recall: 0.7679, F1: 0.7700\n",
      "Epoch 9/15, Loss: 0.5569, Train Acc: 77.74%, Precision: 0.7846, Recall: 0.7774, F1: 0.7793\n",
      "Epoch 10/15, Loss: 0.5147, Train Acc: 79.92%, Precision: 0.8064, Recall: 0.7992, F1: 0.8009\n",
      "Epoch 11/15, Loss: 0.4547, Train Acc: 82.78%, Precision: 0.8339, Recall: 0.8278, F1: 0.8291\n",
      "Epoch 12/15, Loss: 0.3906, Train Acc: 85.06%, Precision: 0.8572, Recall: 0.8506, F1: 0.8519\n",
      "Epoch 13/15, Loss: 0.3570, Train Acc: 86.57%, Precision: 0.8713, Recall: 0.8657, F1: 0.8667\n",
      "Epoch 14/15, Loss: 0.3508, Train Acc: 86.85%, Precision: 0.8735, Recall: 0.8685, F1: 0.8693\n",
      "Epoch 15/15, Loss: 0.3348, Train Acc: 87.26%, Precision: 0.8789, Recall: 0.8726, F1: 0.8736\n",
      "Test Accuracy: 89.96%, Precision: 0.9031, Recall: 0.8996, F1: 0.8999\n",
      "Confusion Matrix:\n",
      " [[514  78   4]\n",
      " [ 15 571  54]\n",
      " [  2  27 527]]\n"
     ]
    }
   ],
   "source": [
    "model4 = CNNModel_more_filters(num_classes=3)\n",
    "trained_model4 = train_and_evaluate_more_metrics(model4, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model4.state_dict(), \"model4.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwiększenie warstw o jeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_more_layers(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel_more_layers, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Nowa warstwa MaxPooling\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 512),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # zapobieganie overfittingowi\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "cuda:0\n",
      "Epoch 1/15, Loss: 0.8792, Train Acc: 57.68%, Precision: 0.5844, Recall: 0.5768, F1: 0.5758\n",
      "Epoch 2/15, Loss: 0.7073, Train Acc: 69.27%, Precision: 0.6999, Recall: 0.6927, F1: 0.6944\n",
      "Epoch 3/15, Loss: 0.6039, Train Acc: 75.47%, Precision: 0.7595, Recall: 0.7547, F1: 0.7554\n",
      "Epoch 4/15, Loss: 0.4811, Train Acc: 81.17%, Precision: 0.8141, Recall: 0.8117, F1: 0.8120\n",
      "Epoch 5/15, Loss: 0.3813, Train Acc: 85.35%, Precision: 0.8555, Recall: 0.8535, F1: 0.8537\n",
      "Epoch 6/15, Loss: 0.3366, Train Acc: 87.11%, Precision: 0.8736, Recall: 0.8711, F1: 0.8714\n",
      "Epoch 7/15, Loss: 0.2993, Train Acc: 88.46%, Precision: 0.8874, Recall: 0.8846, F1: 0.8849\n",
      "Epoch 8/15, Loss: 0.3043, Train Acc: 88.72%, Precision: 0.8889, Recall: 0.8872, F1: 0.8874\n",
      "Epoch 9/15, Loss: 0.2644, Train Acc: 89.75%, Precision: 0.9004, Recall: 0.8975, F1: 0.8979\n",
      "Epoch 10/15, Loss: 0.2349, Train Acc: 91.20%, Precision: 0.9138, Recall: 0.9120, F1: 0.9122\n",
      "Epoch 11/15, Loss: 0.2581, Train Acc: 90.29%, Precision: 0.9056, Recall: 0.9029, F1: 0.9032\n",
      "Epoch 12/15, Loss: 0.2018, Train Acc: 92.37%, Precision: 0.9254, Recall: 0.9237, F1: 0.9239\n",
      "Epoch 13/15, Loss: 0.1837, Train Acc: 93.17%, Precision: 0.9331, Recall: 0.9317, F1: 0.9319\n",
      "Epoch 14/15, Loss: 0.1799, Train Acc: 93.29%, Precision: 0.9339, Recall: 0.9329, F1: 0.9330\n",
      "Epoch 15/15, Loss: 0.1812, Train Acc: 93.07%, Precision: 0.9318, Recall: 0.9307, F1: 0.9308\n",
      "Test Accuracy: 93.02%, Precision: 0.9342, Recall: 0.9302, F1: 0.9308\n",
      "Confusion Matrix:\n",
      " [[535   1  61]\n",
      " [  0 519  34]\n",
      " [ 15  14 613]]\n"
     ]
    }
   ],
   "source": [
    "model5 = CNNModel_more_layers(num_classes=3)\n",
    "trained_model5 = train_and_evaluate_more_metrics(model5, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(treined_model5.state_dict(), \"model5.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6\n",
    "W stosunku do modelu 5 zmniejszono dropout do 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_more_layers_lower_dropout(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel_more_layers_lower_dropout, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) \n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "cuda:0\n",
      "Epoch 1/15, Loss: 0.8678, Train Acc: 59.23%, Precision: 0.6008, Recall: 0.5923, F1: 0.5919\n",
      "Epoch 2/15, Loss: 0.5794, Train Acc: 77.43%, Precision: 0.7770, Recall: 0.7743, F1: 0.7747\n",
      "Epoch 3/15, Loss: 0.4188, Train Acc: 84.04%, Precision: 0.8425, Recall: 0.8404, F1: 0.8406\n",
      "Epoch 4/15, Loss: 0.3466, Train Acc: 87.32%, Precision: 0.8754, Recall: 0.8732, F1: 0.8733\n",
      "Epoch 5/15, Loss: 0.3056, Train Acc: 88.86%, Precision: 0.8909, Recall: 0.8886, F1: 0.8888\n",
      "Epoch 6/15, Loss: 0.2469, Train Acc: 90.52%, Precision: 0.9069, Recall: 0.9052, F1: 0.9054\n",
      "Epoch 7/15, Loss: 0.2515, Train Acc: 90.58%, Precision: 0.9075, Recall: 0.9058, F1: 0.9060\n",
      "Epoch 8/15, Loss: 0.2198, Train Acc: 91.49%, Precision: 0.9159, Recall: 0.9149, F1: 0.9149\n",
      "Epoch 9/15, Loss: 0.1777, Train Acc: 93.32%, Precision: 0.9338, Recall: 0.9332, F1: 0.9332\n",
      "Epoch 10/15, Loss: 0.1618, Train Acc: 94.11%, Precision: 0.9415, Recall: 0.9411, F1: 0.9412\n",
      "Epoch 11/15, Loss: 0.1476, Train Acc: 94.47%, Precision: 0.9452, Recall: 0.9447, F1: 0.9448\n",
      "Epoch 12/15, Loss: 0.1360, Train Acc: 94.98%, Precision: 0.9501, Recall: 0.9498, F1: 0.9498\n",
      "Epoch 13/15, Loss: 0.1363, Train Acc: 95.21%, Precision: 0.9524, Recall: 0.9521, F1: 0.9522\n",
      "Epoch 14/15, Loss: 0.1217, Train Acc: 95.64%, Precision: 0.9565, Recall: 0.9564, F1: 0.9564\n",
      "Epoch 15/15, Loss: 0.1095, Train Acc: 96.05%, Precision: 0.9606, Recall: 0.9605, F1: 0.9605\n",
      "Test Accuracy: 95.15%, Precision: 0.9516, Recall: 0.9515, F1: 0.9515\n",
      "Confusion Matrix:\n",
      " [[569   0  28]\n",
      " [  3 536  14]\n",
      " [ 32  10 600]]\n"
     ]
    }
   ],
   "source": [
    "model6 = CNNModel_more_layers_lower_dropout(num_classes=3)\n",
    "trained_model6 = train_and_evaluate_more_metrics(model6, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model6.state_dict(), \"model6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zapis modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "torch.save(model2.state_dict(), \"model2.pth\")\n",
    "torch.save(model3.state_dict(), \"model3.pth\")\n",
    "torch.save(trained_model.state_dict(), \"trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odczyt modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Załaduj model do tej samej architektury\n",
    "model = CNNModel(num_classes=3)  # Musisz utworzyć model przed wczytaniem wag\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()  # Ustawienie modelu w tryb ewaluacji (nie treningu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inne podejście do balansowania\n",
    "Użycie weightedSampler aby dodać bias do częstości wybierania pocszczególnych elementów z różnych klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AVM': 0, 'Ulcer': 1, 'Normal': 2}\n"
     ]
    }
   ],
   "source": [
    "def save_to_list():\n",
    "    output_root = \"..\\\\output\"\n",
    "    X = []\n",
    "    y = []\n",
    "    label_to_index = {\n",
    "        label: idx for idx, label in enumerate({'AVM', 'Normal', 'Ulcer'})\n",
    "    }\n",
    "    print(label_to_index)\n",
    "    for root, _, files in os.walk(output_root):\n",
    "        for file in files:\n",
    "            if file.endswith(\".bmp\"): \n",
    "                input_path = os.path.join(root, file)\n",
    "\n",
    "                base, ext = os.path.splitext(file)\n",
    "                new_filename = f\"{base}{ext}\"\n",
    "                image = cv2.imread(input_path)\n",
    "\n",
    "                X.append(image)\n",
    "                y.append(label_to_index[new_filename.split(\"_\")[0]])\n",
    "    return X, y\n",
    "\n",
    "X, y = save_to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=123, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),          \n",
    "    transforms.RandomRotation((-180,180)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),                  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])  # do testów - bez zmian\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(X_train, y_train, transform=train_transform)\n",
    "test_dataset = ImageDataset(X_test, y_test, transform=test_transform)\n",
    "\n",
    "class_counts = np.bincount(y)  \n",
    "class_weights = 1.0 / class_counts \n",
    "\n",
    "sample_weights_tr = [class_weights[label] for label in y_train]\n",
    "sample_weights_ts = [class_weights[label] for label in y_test]\n",
    "\n",
    "samplertr = WeightedRandomSampler(sample_weights_tr, num_samples= len(sample_weights_tr), replacement=True)\n",
    "samplerts = WeightedRandomSampler(sample_weights_ts, num_samples= len(sample_weights_ts), replacement=True)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler = samplertr)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, sampler = samplerts)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCNNModel\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(CNNModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 28 * 28, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "model_A = CNNModel(num_classes=3)\n",
    "trained_model_A = train_and_evaluate_more_metrics(model_A, train_loader, test_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_model_A.state_dict(), \"trained_model_A.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Transfer Learning\n",
    "Czasami nie opaca się trenować modelu od zera. Transfer Learning polega na użyciu wytrenowanego modelu i wycięcie ostatnich warstw i zastąpienie ich nowymi. Jest to lepsze dla datasetów z względnie niedużą ilością zdjęć, dlatego użyjemy go wraz z drugim sposobem balansowania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy modelu ResNet50 który jest jednym z lepszych modeli do wyboru dla naszych celów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Transfer(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet50Transfer, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for name, param in self.base_model.named_parameters():\n",
    "            if \"layer4\" in name or \"layer3\" in name: \n",
    "                param.requires_grad = True\n",
    "\n",
    "        in_features = self.base_model.fc.in_features \n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/15: 100%|██████████| 72/72 [00:26<00:00,  2.68it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4798, Acc: 0.8124 | Val Loss: 1.2805, Acc: 0.6673\n",
      "Confusion Matrix:\n",
      " [[166   0   0]\n",
      " [ 31 144   0]\n",
      " [125   8  19]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 72/72 [00:27<00:00,  2.66it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2909, Acc: 0.8916 | Val Loss: 0.1300, Acc: 0.9655\n",
      "Confusion Matrix:\n",
      " [[156   1   8]\n",
      " [  0 173   1]\n",
      " [  1   6 147]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2418, Acc: 0.9138 | Val Loss: 0.1760, Acc: 0.9432\n",
      "Confusion Matrix:\n",
      " [[156   6   6]\n",
      " [  0 181   0]\n",
      " [  7   9 128]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 72/72 [00:27<00:00,  2.67it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1871, Acc: 0.9295 | Val Loss: 0.1692, Acc: 0.9594\n",
      "Confusion Matrix:\n",
      " [[150   5   6]\n",
      " [  0 158   0]\n",
      " [  5   4 165]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 72/72 [00:27<00:00,  2.62it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1527, Acc: 0.9539 | Val Loss: 0.1548, Acc: 0.9615\n",
      "Confusion Matrix:\n",
      " [[151   0  11]\n",
      " [  0 167   8]\n",
      " [  0   0 156]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 72/72 [00:27<00:00,  2.65it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1382, Acc: 0.9539 | Val Loss: 0.1795, Acc: 0.9229\n",
      "Confusion Matrix:\n",
      " [[158   0   0]\n",
      " [  8 158   7]\n",
      " [ 19   4 139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 72/72 [00:27<00:00,  2.65it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1159, Acc: 0.9626 | Val Loss: 0.1221, Acc: 0.9533\n",
      "Confusion Matrix:\n",
      " [[156   0  14]\n",
      " [  0 144   9]\n",
      " [  0   0 170]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 72/72 [00:27<00:00,  2.62it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1224, Acc: 0.9604 | Val Loss: 0.0746, Acc: 0.9716\n",
      "Confusion Matrix:\n",
      " [[151   0   1]\n",
      " [  1 164   4]\n",
      " [  4   4 164]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0927, Acc: 0.9678 | Val Loss: 0.0669, Acc: 0.9777\n",
      "Confusion Matrix:\n",
      " [[164   0   3]\n",
      " [  6 156   0]\n",
      " [  2   0 162]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 72/72 [00:27<00:00,  2.63it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0911, Acc: 0.9665 | Val Loss: 0.0932, Acc: 0.9594\n",
      "Confusion Matrix:\n",
      " [[145   0   5]\n",
      " [  3 169  11]\n",
      " [  0   1 159]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 72/72 [00:27<00:00,  2.65it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0929, Acc: 0.9700 | Val Loss: 0.0228, Acc: 0.9959\n",
      "Confusion Matrix:\n",
      " [[158   0   0]\n",
      " [  0 162   0]\n",
      " [  1   1 171]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 72/72 [00:27<00:00,  2.60it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0830, Acc: 0.9769 | Val Loss: 0.0489, Acc: 0.9797\n",
      "Confusion Matrix:\n",
      " [[167   0   2]\n",
      " [  0 163   2]\n",
      " [  6   0 153]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 72/72 [00:27<00:00,  2.66it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0732, Acc: 0.9765 | Val Loss: 0.0516, Acc: 0.9838\n",
      "Confusion Matrix:\n",
      " [[168   0   3]\n",
      " [  0 172   0]\n",
      " [  2   3 145]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 72/72 [00:27<00:00,  2.59it/s]\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0727, Acc: 0.9743 | Val Loss: 0.0380, Acc: 0.9959\n",
      "Confusion Matrix:\n",
      " [[175   0   1]\n",
      " [  0 170   0]\n",
      " [  0   1 146]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 72/72 [00:27<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0597, Acc: 0.9822 | Val Loss: 0.0226, Acc: 0.9959\n",
      "Confusion Matrix:\n",
      " [[165   0   1]\n",
      " [  0 167   0]\n",
      " [  0   1 159]]\n",
      "Best model updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet50Transfer(num_classes=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "num_epochs = 15\n",
    "best_val_loss = float('inf')\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())  # <-- fix here\n",
    "\n",
    "    test_conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", test_conf_matrix)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        print(\"Best model updated\")\n",
    "\n",
    "# Load best model for testing or saving\n",
    "model.load_state_dict(best_model_weights)\n",
    "torch.save(model.state_dict(), \"resnet50_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\czare\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet50Transfer(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = ResNet50Transfer(num_classes=3).to(device)\n",
    "model.load_state_dict(torch.load(\"best_resnet50_model.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wybór modelu\n",
    "\n",
    "Jak widać najlepszym modelem okazał się być model transfer learningowy z dokładnością 99.5% i tylko jedną poważną pomyłką (sklasyfikowanie jednej z chorób jako brak choroby) także najprawdopodobniej będziemy kontynuować jego rozwój"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
